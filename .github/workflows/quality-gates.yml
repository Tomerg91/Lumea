name: Quality Gates & Performance CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  NODE_VERSION: '20'
  CACHE_VERSION: 'v1'

jobs:
  # ====================== QUALITY GATE 1: CODE QUALITY ======================
  code-quality:
    name: Code Quality Gate
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Shallow clones should be disabled for better analysis

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run ESLint with annotations
      run: |
        npm run lint -- --format=@microsoft/eslint-formatter-sarif --output-file=eslint-results.sarif
      continue-on-error: true

    - name: Upload ESLint results to GitHub
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: eslint-results.sarif
        wait-for-processing: true

    - name: TypeScript Check
      run: npm run typecheck

    - name: Prettier Check
      run: npx prettier --check "**/*.{ts,tsx,js,jsx,json,md}"

    - name: Dependency Audit
      run: npm audit --audit-level=moderate

    - name: Check for outdated dependencies
      run: npm outdated || true

    # Quality gate failure conditions
    - name: Fail on critical issues
      run: |
        # Check if there are any high severity vulnerabilities
        if npm audit --audit-level=high --json | jq -e '.vulnerabilities | length > 0'; then
          echo "High severity vulnerabilities found!"
          exit 1
        fi

  # ====================== QUALITY GATE 2: SECURITY ======================
  security-scan:
    name: Security Gate
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run security audit
      run: npm run security:audit

    - name: Check for secrets in code
      uses: trufflesecurity/trufflehog@main
      with:
        path: ./
        base: main
        head: HEAD
        extra_args: --debug --only-verified

    - name: CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        languages: javascript

  # ====================== QUALITY GATE 3: TESTING ======================
  testing:
    name: Testing Gate
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        test-type: [unit, integration, e2e]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Install Playwright browsers
      if: matrix.test-type == 'e2e'
      run: npx playwright install --with-deps

    - name: Run unit tests
      if: matrix.test-type == 'unit'
      run: npm run test -- --coverage --reporter=json --outputFile=coverage.json

    - name: Run integration tests
      if: matrix.test-type == 'integration'
      run: npm run test:integration

    - name: Run E2E tests
      if: matrix.test-type == 'e2e'
      run: npx playwright test

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.test-type }}
        path: |
          test-results/
          coverage/
          playwright-report/

    - name: Upload coverage to Codecov
      if: matrix.test-type == 'unit'
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage/coverage-final.json
        flags: unittests
        name: codecov-umbrella

    # Quality gate: Require 80% test coverage
    - name: Check coverage threshold
      if: matrix.test-type == 'unit'
      run: |
        COVERAGE=$(jq '.total.lines.pct' coverage/coverage-summary.json)
        if (( $(echo "$COVERAGE < 80" | bc -l) )); then
          echo "Coverage $COVERAGE% is below 80% threshold!"
          exit 1
        fi

  # ====================== QUALITY GATE 4: PERFORMANCE ======================
  performance:
    name: Performance Gate
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Build for production
      run: npm run build

    - name: Analyze bundle size
      run: |
        npm run analyze:bundle:ci
        echo "Bundle analysis complete"

    - name: Bundle size check
      run: |
        # Check if bundle size exceeds thresholds
        MAIN_SIZE=$(du -k client/dist/assets/*.js | sort -n | tail -1 | cut -f1)
        if [ $MAIN_SIZE -gt 1024 ]; then  # 1MB threshold
          echo "Main bundle size ${MAIN_SIZE}KB exceeds 1MB threshold!"
          exit 1
        fi

    - name: Lighthouse CI
      uses: treosh/lighthouse-ci-action@v10
      with:
        configPath: './lighthouserc.json'
        uploadArtifacts: true
        temporaryPublicStorage: true

    - name: Performance budget check
      run: |
        # Parse Lighthouse results and check budgets
        if [ -f ".lighthouseci/lighthouse-results.json" ]; then
          PERFORMANCE_SCORE=$(jq '.[] | select(.categories.performance) | .categories.performance.score * 100' .lighthouseci/lighthouse-results.json)
          if (( $(echo "$PERFORMANCE_SCORE < 90" | bc -l) )); then
            echo "Performance score $PERFORMANCE_SCORE is below 90 threshold!"
            exit 1
          fi
        fi

  # ====================== QUALITY GATE 5: BUILD & DEPLOY ======================
  build-and-validate:
    name: Build Validation Gate
    runs-on: ubuntu-latest
    needs: [code-quality, security-scan, testing, performance]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Build client
      run: npm run build --workspace=client

    - name: Build server
      run: npm run build --workspace=server

    - name: Docker build test
      run: |
        # Test if Docker builds work (without pushing)
        if [ -f "Dockerfile" ]; then
          docker build -t test-build .
        fi

    - name: Health check validation
      run: |
        # Start the server and check health endpoints
        npm run start --workspace=server &
        SERVER_PID=$!
        sleep 10
        
        # Check health endpoint
        curl -f http://localhost:3001/health || (kill $SERVER_PID && exit 1)
        
        kill $SERVER_PID

  # ====================== QUALITY GATE 6: RELEASE VALIDATION ======================
  release-validation:
    name: Release Validation Gate
    runs-on: ubuntu-latest
    needs: [build-and-validate]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Semantic Release Dry Run
      run: npx semantic-release --dry-run
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Generate changelog
      run: |
        # Generate changelog for this release
        npx conventional-changelog -p angular -i CHANGELOG.md -s

    - name: Database migration check
      run: |
        # Validate database migrations
        echo "Checking for pending migrations..."
        # Add actual migration validation logic here

    - name: Environment validation
      run: |
        # Validate environment variables and configurations
        echo "Validating environment configurations..."
        # Add actual environment validation logic here

  # ====================== NOTIFICATION & REPORTING ======================
  notify-results:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [code-quality, security-scan, testing, performance, build-and-validate]
    if: always()
    
    steps:
    - name: Notify Slack on success
      if: success()
      uses: 8398a7/action-slack@v3
      with:
        status: success
        text: '✅ All quality gates passed! Ready for deployment.'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

    - name: Notify Slack on failure
      if: failure()
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        text: '❌ Quality gates failed! Check the workflow for details.'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

    - name: Create issue on failure
      if: failure() && github.ref == 'refs/heads/main'
      uses: actions/github-script@v7
      with:
        script: |
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: 'Quality Gate Failure on Main Branch',
            body: `Quality gates failed on main branch.\n\nWorkflow: ${context.workflow}\nRun: ${context.runNumber}\nCommit: ${context.sha}\n\nPlease investigate and fix the issues.`,
            labels: ['bug', 'ci-failure', 'high-priority']
          })

  # ====================== PERFORMANCE MONITORING ======================
  performance-monitoring:
    name: Performance Monitoring
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Performance regression test
      run: |
        # Compare current performance with baseline
        npm run perf > current-perf.json
        
        # Compare with previous performance data
        # This would typically involve comparing with stored baseline data

    - name: Update performance baseline
      if: success()
      run: |
        # Store current performance as new baseline
        echo "Updating performance baseline..."
        # Implementation would store metrics in a database or artifact